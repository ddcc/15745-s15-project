\documentclass[letterpaper,11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[hyphens]{url}
\usepackage{colortbl}
\usepackage{listings}
\usepackage{graphicx}
\begin{document}

\date{\today}

\title{\Large \bf Memory Safety Bug Hunting with BAP}

\author{Tiffany Bao, Dominic Chen, Rijnard van Tonder}

\maketitle

\section{Introduction}
\label{intro}

\paragraph{The Problem}

\paragraph{}
Although numerous debugging tools have been developed for performing static and
dynamic software analysis, the majority of these require access to source
code or utilization of special compile-time flags to embed debug information
within the output binary. In contrast, little effort has been spent on
developing static binary analysis tools which can directly analyze
off-the-­shelf executables without executing them. For this project, we plan to
focus on a subset of common programming bugs that tend to introduce security
vulnerabilities, known as memory safety errors. Examples of these include
buffer overflows, double frees, and uninitialized variables. In particular, we
define \emph{Security Outcomes} with respect to certain memory-safety errors,
and subsequently implement and test static analyses that yield these outcomes.
All analyses were written against our group's Binary Analysis Platform
(BAP)\footnote{\url{https://github.com/BinaryAnalysisPlatform/bap}}~\cite{bap, brumley2011bap},
and are available online \footnote{\url{https://github.com/ddcc/15745-s15-project}}.

\paragraph{}
A factor of this research area that appeals to many is the ability to
conclude whether vulnerabilities do or do not exist by performing
an analysis purely on the binary level. Due to the inherent difficulties
of operating at this level, %we can expand on what these difficulties are...
our approach to the problem starts out coarse, and continues to be
incrementally refined as we become more familiar with the numerous
barriers that inhibit vulnerability detection in binaries. In this respect,
we have much to say towards lessons learned in \S\ref{lessonslearned}.

\subsection{Approach Overview}
\label{approachoverview}

\paragraph{}
Initially, we planned to implement and test the following static
analyses with respect to our original proposal:

\begin{enumerate}
  \item Intraprocedural data dependency resolution of instructions
  \item Intraprocedural detection of unchecked memory allocations
  \item Basic intraprocedural detection of buffer overflows in the stack
  \item Basic intraprocedural detection of buffer overflows in the heap
\end{enumerate}

\paragraph{}
Equipped with the knowledge of data flow dependencies between instructions (1),
we determined to reason about various properties of typical vulnerabilities
that we could check (2-4). For example, we might like to follow how arguments
to a `strcpy` call are influenced by previous instructions as a function of
the stack register.

\subsection{Related Work}

\paragraph{}
Engler et. al. found numerous bugs with system-specific static analyses,
implemented by way of a meta-compilation language for the \texttt{gcc} compiler
\cite{dawson, dawson2}. Analyses are composed in the form of correctness rules,
and these rules can be automatically inferred from source code. Memory errors that are
checked include NULL pointer bugs, failure to verify return value of allocations, and uses of
already-freed pointers. Similarly, we would ideally like to perform comparable
memory safety analyses, except at the level of binary code. Whereas
Engler's work matured into a generic platform for specifying analyses, we must
start first with an ad-hoc approach to gain insight and familiarity with the
problem domain presented by binaries.

The Jakstab framework~\cite{kinder2008jakstab} provides a platform for
analyzing binaries. However, it is not oriented toward detecting security
vulnerabilities, but rather recovering abstractions from binaries (e.g.,
CFG reconstruction). Frama-C is an example of a framework which
allows one to check various properties, including security properties,
but works on the source level~\cite{cuoq2012frama}.

\subsection{Contributions}

Our key technical contributions are as follows:

\begin{enumerate}
  \item A dataflow analysis framework for BAP.
  \item General plugins for BAP that deliver
    \begin{enumerate}
      \item reaching definitions, and
      \item data flow dependency resolution (use-def and def-use chains).
      \item registers corresponding to function call arguments and returns,
            according to the ARM ABI.
    \end{enumerate}
  \item Security-specific plugins for BAP that produce security outcomes by checking
    \begin{enumerate}
      \item whether memory allocation checks are performed on `memcpy`,
      \item whether calls such as strcpy are safe from buffer overflows under
        specific conditions, and
      \item whether access to heap-allocated memory is in-bounds.
    \end{enumerate}
  \item Results of testing the aforementioned plugins on the \texttt{GNU Coreutils}\footnote{\url{https://www.gnu.org/software/coreutils/}}
    software suite.
\end{enumerate}

\subsection{Structure}

\paragraph{}
Due to the exploratory nature of this project on the binary level, we
concentrated much of our efforts on examining various analysis approaches,
rather than optimizing or improving the scope of a specific analysis.
benchmarks.
\section{Approach}

\subsection{Overview}
\paragraph{}
Here we discuss our approach towards ensuring security properties as it evolved
over the course of the project. Initially, we decided to reason about each
of the cases in \S\ref{approachoverview} that relate to vulnerabilities
(2-4). In order to do so, we needed some basic infrastructure (1), which will be
described shortly. Afterwards, we describe our specific approach to performing
security analyses with respect to our \emph{Security Outcomes}.

\subsection{The Case for Reaching Definitions}

\paragraph{}
For example, consider the following code, for which we desire to verify
that the return value of \texttt{malloc} is checked:

\begin{center}
\lstset{language=C, label=malloccheck,
caption=malloc.c, breaklines=true, basicstyle=\tiny, numbers=left}
\begin{lstlisting}
#include <stdlib.h>
#include <stdio.h>

int main() {
  char *array = 0;

  array = malloc(32 * sizeof(*array));

  if (!array)
    return -1;

  free(array);

  return 0;
}
\end{lstlisting}
\end{center}

\paragraph{}
The disassembly of this binary might appear as follows (with two basic blocks,
before and after the call):

\begin{center}
\lstset{language=C, label=mallocdisasm,
caption=Malloc disassembly, breaklines=true, basicstyle=\tiny, numbers=none}
\begin{lstlisting}
  begin(main_ENTRY)
      000082c8: 04 e0 2d e5    str lr, [sp, #-4]!
      000082cc: 20 00 a0 e3    mov r0, #0x20
      000082d0: 49 00 00 eb    bl #0x124           \; call malloc
  end(main_ENTRY)

  begin(main_0xc)
      000082d4: 00 00 50 e3    cmp r0, #0x0        \; check malloc return value
      000082d8: 02 00 00 0a    beq #0x8
  end(main_0xc)
\end{lstlisting}
\label{fig:malloc}
\end{center}

\paragraph{}
We would like to confirm that a check takes place after the call to malloc;
i.e.; we want to check for the presence of a \texttt{cmp} instruction and the
operand \texttt{r0} in \texttt{main\_0xc}.

\paragraph{}
However, it may be the case that the contents of \texttt{r0} are first
moved to another register, \texttt{r3}, which is subsequently checked by the
\texttt{cmp} instruction. In order to detect an unchecked \texttt{malloc}
return value, we must verify that there exists a flow of data from
\texttt{r0} to other registers that is also unchecked. To obtain the statements
where data from \texttt{r0} flows to, we make use of def-use chains. For the
definition of \texttt{r0} in the BIL IR, we check all uses of \texttt{r0} and
transitively look up the def-use chains for further registers, such as
\texttt{r3}, which the value in \texttt{r0} flows to. On the final set of
instructions, we verify that the data is subject to a \texttt{cmp} instruction.

\paragraph{}
This example demonstrates the need for def-use chains; our stack and heap based
analyses in turn also require use-def chains. Due to backwards edges in the
CFG, it is difficult to produce def-use chains given a single instruction. For
this reason we first implemented a dataflow framework and a
reaching-definitions pass. A more comprehensive description of the
dataflow framework implementation, as written in OCaml for
BAP, may be viewed in Appendix~\ref{appa1}.
From the reaching definitions results, we generate def-use
and use-def chains as necessary---e.g., we filter on those reaching definitions
which concern a particular use or def of a register.

\subsection{Data Flow Dependency}

\paragraph{}
An extension to the def-use and use-def chains was to produce the data (flow)
dependencies of a given statement in a forward or backward direction,
respectively. Essentially, given a register in a definition (such as a \texttt{mov}
instruction in the BIL IR), we can produce a set of all instructions that are
determined to transitively affect its value. We implement this
by way of a data dependency plugin for BAP. Consider the arguments to the
following \texttt{strcpy} call:

\begin{center}
\lstset{language=C, label=strcpy_src,
caption=strcpy.c, breaklines=true, basicstyle=\tiny, numbers=none}
\begin{lstlisting}
#include <stdio.h>
#include <string.h>

int main(int argc, char** argv) {
  char dst[10] = {0};
  strcpy(dst, argv[1]);
}
\end{lstlisting}
\end{center}

For the \texttt{dst} variable on the stack, encoded as an
\texttt{<address,statement>} pair, we have:

\tiny
\begin{verbatim}
    <(0x8490:32, 0)> R0 := R2
\end{verbatim}
\normalsize

The plugin will determine all preceding instructions it is dependent on:

\tiny
\begin{verbatim}
    <(0x8444:32, 3)> SP := SP - 0x8:32
    <(0x8448:32, 2)> R11 := SP + 0x4:32
    <(0x848C:32, 2)> R2 := R11 - 0x10:32
\end{verbatim}
\normalsize

\paragraph{}
Now, we can observe the role that the stack pointer \texttt{SP} plays
when considering \texttt{dst}. A full listing of the BIL disassembly,
the data dependencies for \texttt{argv[1]}, and a graphical
output may be viewed in the Appendix~\ref{appa2}.

\subsection{\texttt{malloc} Checking Security Outcomes}
\input{mallocchecking}
\subsection{Stack-based Security Outcomes}
\label{stackoutcomes}

\paragraph{}
A number of unfruitful approaches as documented in~\S\ref{lessonslearned} lead us
to opting for an approach where we identify two properties which are important
from a security perspective, without inferring sizes of stack-based buffers.

\paragraph{\texttt{src} is a constant}
If we can determine that the \texttt{src} buffer is a constant, (and therefore
not dependent on any user input), the \texttt{strcpy} call is safe. While a
good property to check, it was found that a constant value corresponding to the
\texttt{src} argument didn't occur in practice. Depending on compiler
optimizations \texttt{strcpy} (as well as \texttt{sprintf} calls) would be
compiled to a \texttt{LDMIA.W} ARM instruction which directly copies memory.
Lastly, we observed that \texttt{strcpy} and \texttt{sprintf} may be replaced
by the \texttt{\_\_strcpy\_chk} and \texttt{\_\_sprintf\_chk} counterparts,
which are less interesting to analyze from a security standpoint.

\paragraph{}
Nevertheless, we implemented a partial check of this case in the plugin, and
assumed the standpoint that any \texttt{src} address originating from the
\texttt{ro.data} section implies a constant, fixed value. However, for this
check we only consider the statement which loads a value immediately before the
call, and not originating previous statements. % because memory and interfering statements

\paragraph{Stack accesses within the frame}
For this outcome, we confirm that all instructions which access elements on
the stack, plus a fixed offset, are within the stack range of a function. We
infer the size of the frame by considering the statements that manipulate
SP in the function prologue. While we didn't observe any cases where the
stack range was exceeded, this type of check forms the basis for further,
more sophisticated improvements.

\subsection{Heap-based Security Outcomes}
\paragraph{}
Another common memory safety problem is reading or writing to memory
exceeding an allocated buffer; in certain situations, these buffer overflows
are remotely exploitable and can be leveraged by an attacker to take control
of a given program. As a result, we decided to implement a basic heap check
plugin for the Binary Analysis Platform (BAP) that is capable of identifying
and warning when static program execution violates heap safety.

\paragraph{}
Another common memory safety problem is reading or writing to memory
The below example program, known as \texttt{doublefree}, suffers from a number of
common memory safety problems. Among these is an out of bounds array write to
the \texttt{array} variable, demonstrating a common off-by-one error that exceeds
the allocated buffer size by one byte. Additionally, this program also
exemplifies a number of other memory safety issues that we have developed BAP
plugins to detect, including a missing return value check for the call to
\texttt{malloc}.

\begin{center}
\lstset{language=C, label=freefree,
caption=malloc\_free.c, breaklines=true, basicstyle=\tiny, numbers=left}
\begin{lstlisting}
#include <stdlib.h>
#include <stdio.h>

int main() {
 char *array;
 printf(“Hello World!\n”);

 // Use of uninitialized memory
 printf("Pointer: %p\n", array);

 // Missing check against NULL return value
 array = malloc(32 * sizeof(*array));

 // Out of bounds array access
 array[32] = 0;

 // Double free
 free(array);
 free(array);

 return 0;
}
\end{lstlisting}
\end{center}

\paragraph{}
At the most basic level, the \texttt{heap\_check} plugin functions by searching for calls to
external library functions responsible for performing memory allocation such as
\texttt{malloc}, \texttt{xmalloc}, \texttt{calloc}, etc. Then, it queries the
BAP ABI interface to determine the number of arguments passed to the library
function, and the register that contains the return value. Template matching is
used to identify the specific argument that contains the allocation size, since
the former two functions take only one argument, whereas the latter takes two
arguments, with the allocation size passed in the second argument.

\paragraph{}
At this point, the program searches backwards through the function from the
callsite for the most recent definition of the register that contains the
allocation size, and analyses this definition to determine if it can statically
identify a constant allocation size. If this is the case, then the plugin tags
this allocation callsite with the size of the allocation, and proceeds to the
next allocation callsite. If it cannot statically determine the allocation
size, then the program currently tags the allocation callsite with an
allocation size \texttt{MAX\_INT}, essentially performing widening to the supremum of the
semilattice.

\paragraph{}
Next, after identifying and tagging all of the memory allocation callsites, the
plugin iterates through each of the callsites, and attempts to statically
identify all possible uses of the return value register that involve a memory
operation (e.g. LDR and STR assembly instructions). For each of these uses, the
plugin identifies the register that contains the memory address, searches
backwards from the memory instruction for the most recent definition of this
register, and statically attempts to determine the register offset from the
allocation site. This process is similar to that performed above for
determining the size of a memory allocation.

\paragraph{}
Finally, if the program was able to statically identify both the memory
allocation size and the memory operation offset, the program compares the two
values to ensure that the operation is less than the allocation size. If this
is not the case, the program emits a warning about this unsafe memory
operation, otherwise it labels the operation safe and proceeds to the next use.

\paragraph{}
Since the current BAP framework lacks a number of memory optimizations that
would simplify analysis, this plugin currently only performs a basic level of
memory operation checking. In particular, it currently only analyzes memory
write operations, and is restricted to simple memory offset computations that
only involve addition. As a result, it cannot perform analysis on loop
operations or complex assembly sequences in which the pointer to the memory
allocation is stored into memory or selectively modified through indirect
control flow. Nevertheless, the current plugin is capable of identifying memory
safety vulnerabilities for the example program shown above, as shown below.


\tiny
\begin{verbatim}
0x8330:32: .init_proc ([832c, 8333]) -> call_weak_fn ([83dc, 83f3])
0x83C8:32: _start ([83a0, 83cb]) -> __libc_start_main ([837c, 8387])
0x83CC:32: _start ([83cc, 83cf]) -> abort ([8394, 839f])
0x83F4:32: call_weak_fn ([83f4, 83f7]) -> __gmon_start__ ([8388, 8393])
0x848C:32: __do_global_dtors_aux ([848c, 848f]) -> deregister_tm_clones ([8400, 8417])
0x84C8:32: frame_dummy ([84c4, 84cb]) -> register_tm_clones ([8438, 8457])
0x84E4:32: main ([84d4, 84e7]) -> puts ([8364, 836f])
0x84F0:32: main ([84e8, 84f3]) -> printf ([834c, 8357])
0x84F8:32: main ([84f4, 84fb]) -> malloc ([8370, 837b])
>> 0x84F8:32: malloc (0x20:32)
0x8518:32: main ([84fc, 851b]) -> free ([8358, 8363])
0x8520:32: main ([851c, 8523]) -> free ([8358, 8363])
>> 0x84FC:32: R3 = R0
>> 0x8508:32: R3 = R3 + 0x20:32
>> 0x8510:32: R3 + 0x0:32 <- t_1605 (UNSAFE: 0x20:32 <= 0x20:32)
0x8560:32: __libc_csu_init ([853c, 8563]) -> .init_proc ([832c, 8333])
\end{verbatim}
\normalsize

The above plugin output identifies addresses at which calls were made from one
function to another using the \texttt{->} (arrow) symbol, labeling both the source and
destination function with their symbol name and relevant basic blocks. Then, for
each memory allocation callsite, the program attempts to statically determine
the allocation size, shown above with the \texttt{malloc (0x20:32)} syntax.
Subsequently, the program attempts to statically determine the use of each
allocation site, the offset of the memory operation, and the actual memory
operation, which are respectively shown above by the movement of memory
allocation pointer from \texttt{R0} (the return value of \texttt{malloc})” to \texttt{R3}, the
increment of register \texttt{R3} by \texttt{0x20:32}, and the storage of temporary variable
\texttt{t\_1605} (containing the value \texttt{0} loaded from \texttt{R2}) into \texttt{R3}. At the point, the
plugin identifies that memory operation offset exceeds the size of the
allocation site, and emits a warning that the operation is unsafe (\texttt{UNSAFE:
0x20L32 <= 0x20:32}).

Note that the \texttt{:32} label indicates that the respective memory address is
32-bit.


% ===============================================
\section{Experimental Setup}

\paragraph{}
Our experimental setup consisted of running our plugins with BAP \texttt{0.9.6}
\cite{bap} on a set of binaries, including GNU \texttt{Coreutils} and our
own examples.

\subsection{Unchecked Malloc}

In this experiment, we checked the following property for all arm
\texttt{Coreutils} binaries:
\begin{itemize}
\item after a call instruction with target \texttt{malloc}, the return value
    must be checked.
\item if the return value is checked to be zero, there must be a conditional
    jump followed to deal with the zero case.
\item the return value of \texttt{malloc} can be passed to other registers. If
    so, checking other register with the return value should be also valid.
\end{itemize}

\subsection{Stack Check Plugin}

\paragraph{}
The stack check plugin was tested against the GNU \texttt{Coreutils} suite. We
primarily chose the \texttt{Coreutils} suite since a) it can be compiled for
ARM, and b) it contains numerous calls to \texttt{strcpy}, \texttt{memcpy},
\texttt{malloc}, and so forth. The stack check plugin, while configurable,
concretely checked for function calls to:

\begin{itemize}
  \item \texttt{strcat}
  \item \texttt{strcpy}
  \item \texttt{strncpy}
  \item \texttt{memcpy}
\end{itemize}

\paragraph{}
The plugin collected a number of statistics on the binaries, including
the number of argument sites (that is, statements that set up registers
before a call), the number of functions which contained calls to `dangerous'
functions, and the maximum number of statements on which an argument
site statement was dependent. These are illustrated in Figure~\ref{fig:corestats}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.55, trim=0mm 0mm 0mm 0mm, clip]{img/coreutils2.pdf}
\caption{Coreutils statistics generated by plugin}
\label{fig:corestats}
\end{figure}

Figure~\ref{fig:coretotal} presents the total number of statements in a binary
which affect unique argument sites.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.45, trim=0mm 0mm 0mm 0mm, clip]{img/coreutilstotal.pdf}
% \caption{Total statements }
\label{fig:coretotal}
\end{figure}

\paragraph{}
The figures illustrate some interesting properties with respect to argument
sites and data dependencies. Consider that each potentially dangerous function
takes 2 or 3 parameters--of these, our data dependency plugin determined the
maximum number of statements a single argument site statement is dependent on.
We observe from Figure~\ref{fig:corestats} that this could number in the hundreds,
whereas the total number could range in the thousands (Figure ~\ref{fig:coretotal}).
The implication here is that any additional reasoning and refinement to static
analysis methods across cases composed of sizable dependencies need to be
carefully considered. For instance, if we add forms of pointer analysis,
we may speculate about the scale of complexity of memory operations for
argument sites.

\paragraph{}
We did not observe any violations with respect to the security outcomes
in~\S\ref{stackoutcomes}. This is perhaps unsurprising, given the ubiquitous
use of the \texttt{Coreutils} suite. At the same time, it is difficult to
choose a test suite which purposefully exhibits the stack properties that we
check; see \S\ref{lessonslearned} for further discussion.

\subsection{Heap Check Plugin}
\paragraph{}
For evaluation of the heap check plugin, we executed the plugin on each
executable from the \texttt{coreutils} suite of system programs. This is
composed of 103 binaries, such as \texttt{cat}, \texttt{wc}, \texttt{who}, etc.
Additionally, we compiled four separate versions of each plugin with different
optimization levels; one at \texttt{O0}, one at \texttt{O1}, one at
\texttt{O2}, and one at \texttt{O3}.

% ======================================================================
\section{Experimental Evaluation}

\paragraph{}
In general, we were pleased that our plugins ran successfully on our own
example binaries as well as \texttt{Coreutils}. A key aspect of evaluating
the success of our project is that we were able to start with a basic API in
BAP, and after implementing a non-trivial amount of `infrastructure' code,
arrive at three individual plugins which are able to produce security outcomes.

\paragraph{}
Our evaluation of these plugins are largely qualitative rather than
quantitative at this stage. However, they serve as very useful data points
toward developing more sophisticated analyses.

\subsection{Malloc Check Plugin}

\begin{figure}[h!]
      \caption{Malloc checking result in coreutils binaries.}
        \centering
    \includegraphics[width=1.0\textwidth]{malloccheckplot}
\end{figure}
So far, we applied our checking on 128 binaries from \texttt{Coreutils}. The
result showed that we found 15 places that \texttt{malloc} is not checked
according to our rules.
\begin{center}
\lstset{language=C, label=strcpy_asm,
caption=Function re\_node\_set\_alloc, breaklines=true, basicstyle=\tiny, numbers=none}
\begin{lstlisting}
0000f910 <re_node_set_alloc>:
    f910:       e92d4010        push    {r4, lr}
    f914:       e1a04000        mov     r4, r0
    f918:       e5801000        str     r1, [r0]
    f91c:       e3a03000        mov     r3, 0
    f920:       e5803004        str     r3, [r0, 4]
    f924:       e1a00101        lsl     r0, r1, 2
    f928:       ebffe6f6        bl      9508 <malloc@plt>
    f92c:       e5840008        str     r0, [r4, 8]
    f930:       e3500000        cmp     r0, 0
    f934:       03a0000c        moveq   r0, 12
    f938:       13a00000        movne   r0, 0
    f93c:       e8bd8010        pop     {r4, pc}
\end{lstlisting}
\end{center}
For example, we found that although the function \texttt{re\_node\_set\_alloc}
compares the return value of \texttt{malloc}, it does not handle the case
where the return value is 0. Instead, the return value will be stored on the
stack and overwrite another value.

\subsection{Stack Check Plugin}

\paragraph{}
As mentioned, our stack check plugin did not trigger any violations when run
over the \texttt{Coreutils} test suite. This result was largely anticipated:
the \texttt{Coreutils} library was chosen so that we could verify that our
plugins run and to rule out the possibility that binaries in \texttt{Coreutils}
exhibited rudimentary flaws.

\paragraph{}
In critique of this plugin, there are a number of stack-based errors that could
occur despite our checks. For example, consider a stack frame containing
multiple local buffers at runtime. It is feasible that a buggy \texttt{strcpy}
call could copy bytes beyond the boundary of a single buffer into an adjacent
buffer, while remaining within the stack bounds. Our plugin would not detect
this case. Consider a further case where memory accesses to the stack
are dependent on general purpose registers---here we cannot conclude
whether the access is within range of the stack frame.

\paragraph{}
A positive side-effect of the plugin is the potential of reusability, and by
extension, refinement toward more sophisticated analyses. Recall that this
plugin collects and makes use of statements that an argument site depends on.
Thus, we have the ability to store the output of our analysis without having to
rerun the plugin. For example, we may be able to couple this data with
pointer-analysis, and infer stack boundaries.

\subsection{Heap Check Plugin}
\paragraph{}
Of this output, our plugin identified a total of 4303 calls to pre-identified
memory allocation functions, namely \texttt{xmalloc}, \texttt{malloc}, \texttt{xrealloc},
\texttt{realloc}, and \texttt{calloc}. Among these, the memory allocation size was
identified for 369 of these callsites, whereas 3934 of these callsites had an
unknown allocation size. Drilling down further, 804 of these unknown callsites
involved left arithmetic shifts (multiplication) on a temporary variable, which
our plugin would likely be able to identify given some additional development
work.  Another 426 of these unknown callsites had an allocation size that was
loaded from memory, which would be difficult resolve without pointer analysis
and significant additional development effort. The remaining 2707 of these
unknown callsites were due to the allocation size value being passed through
more than one register, which our plugin is currently unable to resolve. By
making the callsite identification routine recursive, it is likely that we
would be able to resolve these unknown callsites further into one of the above
subcases.  Below is a sample of the program output demonstrating these
different results:


\tiny
\begin{verbatim}
coreutils_O3_groups.out:182:>> 0xAFFC:32: xmalloc (UNKNOWN: R1)
coreutils_O3_head.out:17:>> 0x9C8C:32: xrealloc (UNKNOWN: t_26405 << 0x2:32)
coreutils_O3_head.out:52:>> 0x9730:32: xmalloc (UNKNOWN: mem[SP + 0x64:32, el]:u32)

coreutils_O3_who.out:335:>> 0xD2D0:32: xmalloc (0x21:32)
\end{verbatim}
\normalsize

\paragraph{}
Of the above callsites with memory allocation sizes that were statically
identified, the memory operation offset was successfully determine and
identified as safe for five of these, as shown below. None were identified as
unsafe, and 301 were unchecked. It is likely that more of these unchecked uses
would be resolvable given additional development effort, since the current
implementation is only capable of resolving additive (and not negative,
multiplicative, etc) offsets to the allocation site. Note that of the five
memory operations identified as safe, all were in the \texttt{O0} version of the
respective \texttt{coreutils} binary, indicating that higher optimization levels are
generating more complex code that currently cannot be resolved.

\tiny
\begin{verbatim}
coreutils_O0_chmod.out:194:>> 0xAF14:32: R3 + 0x0:32 <- t_67547 (UNCHECKED)
coreutils_O0_chmod.out:196:>> 0xAF20:32: R3 + 0x1:32 <- t_67551 (UNCHECKED)
coreutils_O0_chmod.out:198:>> 0xAF2C:32: R3 + 0x4:32 <- R2 (UNCHECKED)
coreutils_O0_chmod.out:200:>> 0xAF38:32: R3 + 0x8:32 <- R2 (UNCHECKED)
coreutils_O0_chmod.out:202:>> 0xAF44:32: R3 + 0xC:32 <- R2 (UNCHECKED)

coreutils_O0_chmod.out:204:>> 0xAF54:32: R3 + 0x1:32 <- t_67567 (SAFE: 0x20:32 > 0x10:32)
coreutils_O0_install.out:1515:>> 0x179BC:32: R3 + 0x1:32 <- t_186264 (SAFE: 0x20:32 > 0x10:32)
coreutils_O0_mkdir.out:176:>> 0xA880:32: R3 + 0x1:32 <- t_36422 (SAFE: 0x20:32 > 0x10:32)
coreutils_O0_mkfifo.out:109:>> 0x9B14:32: R3 + 0x1:32 <- t_25151 (SAFE: 0x20:32 > 0x10:32)
coreutils_O0_mknod.out:125:>> 0xA2B0:32: R3 + 0x1:32 <- t_31175 (SAFE: 0x20:32 > 0x10:32)
\end{verbatim}
\normalsize

% =====================================================================
\section{Surprises and Lessons Learned}
\label{lessonslearned}

There were a number of surprises and lessons learned throughout this project.

\subsection{Development Hurdles}

\paragraph{}
One of the common problems that we encountered while developing our analysis
plugins was a lack of preexisting compiler analysis in the BAP framework. In
particular, since we are performing our analysis at both the assembly and BIL
level, common compiler simplifications like Static Single Assignment (SSA) are
not available, requiring manual implementation of def-use and use-def chains
using the dataflow framework to resolve. Likewise, BAP does not include any
built-in constant propagation or constant folding passes, requiring manual
pattern-matching on arithmetic instructions in an attempt to resolve register
operations to constant values. Furthermore, BAP does not have any built-in
pointer analysis capabilities, and due to time constraints, we did not track
values passed in and out of memory for our analysis.

\paragraph{}
Likewise, due to the rapid development of the BAP framework, we also
encountered problems in which certain APIs that our plugin utilizes were
renamed or modified in the `master` branch of the BAP repository. This
essentially presented a trade-off between spending additional development
effort to revise existing code, and updating to newer version of the BAP
framework to obtain newer features and fix existing bugs.

\subsection{Reasoning about buffer overflows}

\paragraph{}
An initial approach towards ensuring stack buffer overflow detection was to
attempt to reason about sizes of buffers which are passed to ``Potentially
Dangerous Functions''~\cite{seacord2008cert} such as \texttt{strcpy}. This
turned out to be an unfruitful approach for the scope of the project, since one
would have to invariably have to reason about memory accesses.

\paragraph{}
A concrete example that illustrates the difficulty of performing checks on
\texttt{strcpy} was found when we considered \texttt{libxkbfile.so.1.0.2}.
Initially we thought that this is a candidate we could perform our check on,
due to containing a \texttt{strcpy(buf,"none")}~\cite{xorg} call. However, this was found
to compile to the \texttt{LDMIA.W} instructions mentioned before. This example
principally highlights the difficulty in choosing candidates for testing.

\paragraph{}
One surprising result was the great number of statements (over
200) that some argument sites were found to depend on in \texttt{Coreutils}
binaries. It was also the case that this result was exhibited inside large
functions. When testing the plugin on small examples initially, the number of
statements rarely numbered more than 20. As mentioned previously, we speculate
that this will affect

\subsection{Reasoning about heap memory}

\paragraph{}
As mentioned in the discussion of our results, it became apparent that the
number of resolved memory allocations could be significantly improved with
moderate additional development effort. Among these would be incorporating a
more comprehensive constant propagation analysis for resolving memory
allocation sizes, as the current heap check plugin only looks for constant
additive offsets to the base allocation site; as mentioned previously it is
currently incapable of identifying other common arithmetic operations such as
left shifts (multiplication), etc. Likewise, including better tracking of
values from one register to another would likely allow for more memory
allocation sizes to be resolvable into either a constant or a value produced by
a memory operation, which is currently unhandled.

\paragraph{}
Basic memory tracking would likely also improve our results significantly, at
least for the O0 binaries, as we have discovered that the compiler may
occasionally produce a back-to-back memory store followed by a memory load from
the same address. This is currently considered unresolvable.

\subsection{General Things Learned}

In general, this project made clear the difficulty of tackling binary
problems. Specifically, we cannot advance the problem of analyzing binaries
without basic ``building blocks'' which provide information about the security
outcome we wish to address. For each such potential outcome in the future,
we will have to consider critically what types of ``building blocks'' we need,
whether pointer analysis, path-sensitivity, context-sensitivity, etc.

\paragraph{}
We learned that it is more effective in our research to develop our approaches
with respect to security outcomes. By doing so, we incrementally identify the
requirements for producing desired security outcomes (e.g., reaching
definitions, use-def). It also seems to be a pattern that more sophisticated
analyses are built on top of simpler analyses (like those produced in this
project), rather than sophisticated analysis being stand-alone. This follows
because we require more fundamental information before reasoning about
further complexities.

% =====================================================================
\section{Conclusions and Future Work}
\paragraph{}
We will focus specifically on refining the sophistication of our analyses
to handle broader cases as outlined in our discussions. A major benefit of
identifying the limitations in our approach and evaluation is that it
immediately highlights areas of refinement. The additional goals beyond 100\%
in our original proposal are all candidates for formulating future analyses.
In summary, these are:

\begin{itemize}
  \item Implement intraprocedural detection of null pointer dereferences
  \item  Implement detection of dynamic memory errors; e.g. dangling pointers,
double frees, and invalid frees
\item Implement intraprocedural detection of variables with uninitialized
variables; e.g. usage of variables with unassigned values
\item Evaluate soundness, completeness, and performance of our tool
  against similar bug checking tools, e.g. Address Sanitizer, Valgrind
  MemCheck, Clang Static Analyzer, Coverity, CodeSonar, etc.
\end{itemize}

\paragraph{}
From a more general perspective, the scope of our analyses could be improved by
implementing basic support for pointer analysis, interprocedural analysis, and
field-sensitive analysis. For example, a large number of the heap allocations
that are currently resolvable to be a fixed-sized constant are likely being
produced by dynamic memory allocations of custom-defined struct’s. For these
data structures, better granularity would be obtained by performing memory
operation safety analysis not only for the entire allocation, but also for
individual fields within the allocation. This would likely require pointer
analysis plus additional infrastructure to keep track of offsets within the
struct that are commonly accessed.

\paragraph{}
It has been a promising exercise to prototype and test our
analyses within the context of this project. We consider the experience and
insights gained throughout to be particularly valuable for performing continued
research in our group.

% =====================================================================
\section{Distribution of Total Credit}
Even three-way split.

Breakdown:
\begin{enumerate}
 \item Dominic: Implementation of dataflow framework and heap check plugin.
 \item Rijnard: Implementation of data dependencies and stack check plugin.
 \item Tiffany: Implementation of \texttt{malloc} return value check plugin.
\end{enumerate}

\clearpage

\appendix
\section{Appendix}
\label{appa1}
\subsection{Technical Description of the BAP Dataflow framework}

\paragraph{}
Due to the preliminary status of the current BAP framework, a number of common
compiler analyses have not yet been implemented, including a basic dataflow
framework. In particular, BAP currently only includes a disassembly engine
using the LLVM framework, a lifter from ARM/x86/x86\_64 to an intermediate
language known as BIL (BAP Intermediate Language), and a basic semantic
analysis for identifying basic blocks and performing a graph-based traversal
through predecessors and successors.

\paragraph{}
As a result, we spent the first portion of our project implementing a basic
dataflow analysis framework capable of performing both forwards and backwards
dataflow analysis. This was accomplished by first implementing a sparse
Bitvector module capable of representing both the infimum and supremem lattice
elements (e.g. the empty and universal sets). Existing Bitvector
representations in the standard library and Jane Street’s Core library are not
capable of this, because they utilize a fixed-size bit representation for the
Bitvector. As a result, this would require a preliminary pass through each
basic block and each instruction to identify the number of lattice elements in
the Bitvector, reducing performance and flexibility of analysis.

\paragraph{}
In particular, our custom implementation defines a Bitvector record (datatype)
composed of three subvalues: (1) \texttt{infinite}: a boolean value that determines
whether the bitvector is of infinite size, (2) \texttt{value}: a boolean value that
determines whether the bits of the bitvector are 0 or 1, and (3) \texttt{indexes}: a set
of integers that identifies indexes of the bitvector that are set to value. As
a result, this implementation allows for the empty and universal sets to be
respectively identified by the following simple Bitvector values: \texttt{\{infinite:
true, value: false (0), indexes: \{\}\}} and \texttt{\{infinite: true, value: true (1),
indexes: \{\}\}}. Standard Bitvector operations, such as union, intersection, and
difference, are defined using these primitives. As an example, consider an
arbitrary Bitvector a, and the following operations: \texttt{empty - a = empty, a -
empty = a, universal - a = not a, a - universal = empty}. These operations are
straightforward, even for the relative complement of the universal set with the
arbitrary Bitvector; this can be represented by simply toggling the value
attribute from true to false or vice-versa.

\paragraph{}
Specifically, this highlights the idea that each finite Bitvector has two
distinct representations: one with value set to true and indexes containing a
set of bit indexes that are set, and another with value set to false and
indexes containing a set of bit indexes that are unset. Although this does
increase the logical complexity of the implementation, it allows for greater
lattice representation flexibility with decreased memory consumption.

\paragraph{}
Otherwise, the dataflow framework implementation is relatively standardized,
and is built on top of this lattice representation. A pair of maps are defined
for translating unique instruction addresses of BIL or assembly instructions to
lattice values, and vice-versa. This is achieved through the use of a mutable
counter that identifies the unique Bitvector index associated with each
instruction. Then, analysis results from each sequence of BIL instructions are
propagated to each assembly instruction, and subsequently to each basic block,
allowing for analysis granularity at all levels. Users of the framework specify
initial values for each interior and boundary point, the entry block of
analysis, and the direction of the dataflow analysis. Since the BAP framework
is written in a functional language, the user can also pass a user-defined meet
function and transfer function for performing the body of analysis. An internal
worklist is used to keep track of basic blocks that needs to be scheduled for
reanalysis; this is achieved by making the main dataflow analysis function
recursive, and iterating through every basic block on the worklist before
constructing a new worklist from those basic blocks with modified dataflow
lattice values.

\section{Appendix}
\label{appa2}
\paragraph{BIL Dissasembly of Listing \ref{strcpy_asm}}

\begin{verbatim}
  SP := SP - 0x8:32
  mem := mem         with [base_436 + 0xFFFFFFF8:32, el]:u32 <- R11
  mem := mem         with [base_436 + 0xFFFFFFFC:32, el]:u32 <- LR
  base_436 := SP
  R11 := SP + 0x4:32
  t_439 := 0x4:32
  s_438 := SP
  SP := SP - 0x18:32
  t_442 := 0x18:32
  s_441 := SP
  mem := mem         with [R11 + 0xFFFFFFE8:32, el]:u32 <- R0
  mem := mem         with [R11 + 0xFFFFFFE4:32, el]:u32 <- R1
  R3 := R11 - 0x10:32
  t_447 := 0x10:32
  s_446 := R11g
  R2 := 0x0:32
  mem := mem         with [R3 + 0x0:32, el]:u32 <- R2
  R3 := R3 + 0x4:32
  t_452 := 0x4:32
  s_451 := R3
  R2 := 0x0:32
  mem := mem         with [R3 + 0x0:32, el]:u32 <- R2
  R3 := R3 + 0x4:32
  t_457 := 0x4:32
  s_456 := R3
  R2 := 0x0:32
  mem := mem         with [R3 + 0x0:32, el]:u16 <- t_460
  t_460 := low:16[R2]
  R3 := R3 + 0x2:32
  t_463 := 0x2:32
  s_462 := R3
  R3 := mem[R11 + 0xFFFFFFE4:32, el]:u32
  R3 := R3 + 0x4:32
  t_467 := 0x4:32
  s_466 := R3
  R3 := mem[R3 + 0x0:32, el]:u32
  R2 := R11 - 0x10:32
  t_471 := 0x10:32
  s_470 := R11
  R0 := R2
  R1 := R3
  jmp 0x82E0:32
  LR := 0x849C:32
\end{verbatim}

\paragraph{BIL data dependency instructions for \texttt{argv[1]}}

\begin{verbatim}
  <(0x8444:32, 0)> base_436 := SP
  <(0x8444:32, 1)> mem := mem         with [base_436 + 0xFFFFFFFC:32, el]:u32 <- LR
  <(0x8444:32, 2)> mem := mem         with [base_436 + 0xFFFFFFF8:32, el]:u32 <- R11
  <(0x8444:32, 3)> SP := SP - 0x8:32
  <(0x8448:32, 2)> R11 := SP + 0x4:32
  <(0x8450:32, 0)> mem := mem         with [R11 + 0xFFFFFFE8:32, el]:u32 <- R0
  <(0x8454:32, 0)> mem := mem         with [R11 + 0xFFFFFFE4:32, el]:u32 <- R1
  <(0x8458:32, 2)> R3 := R11 - 0x10:32
  <(0x845C:32, 0)> R2 := 0x0:32
  <(0x8460:32, 0)> mem := mem         with [R3 + 0x0:32, el]:u32 <- R2
  <(0x8464:32, 2)> R3 := R3 + 0x4:32
  <(0x8468:32, 0)> R2 := 0x0:32
  <(0x846C:32, 0)> mem := mem         with [R3 + 0x0:32, el]:u32 <- R2
  <(0x8470:32, 2)> R3 := R3 + 0x4:32
  <(0x8474:32, 0)> R2 := 0x0:32
  <(0x8478:32, 0)> t_460 := low:16[R2]
  <(0x8478:32, 1)> mem := mem         with [R3 + 0x0:32, el]:u16 <- t_460
  <(0x8480:32, 0)> R3 := mem[R11 + 0xFFFFFFE4:32, el]:u32
  <(0x8484:32, 2)> R3 := R3 + 0x4:32
  <(0x8488:32, 0)> R3 := mem[R3 + 0x0:32, el]:u32
\end{verbatim}

\paragraph{Graphical output of BIL data dependencies, with highlighted arguments}

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.15, trim=0mm 0mm 780mm 0mm, clip]{img/ddep.pdf}
% \caption{Some caption}
% \label{fig:diagram_description}
\end{figure}

\nocite{*}
{\bibliographystyle{acm}
\bibliography{b1}}

\end{document}
